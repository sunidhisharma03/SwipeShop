{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq5tPo7Iv06D",
        "outputId": "1d9a91ac-0c0a-4817-98da-19e0cf2391ed"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from google.colab import files\n",
        "from IPython.display import display, Image\n",
        "from ultralytics import YOLO\n",
        "from IPython import display as ipython_display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkWh1jCdv3Kk",
        "outputId": "06b47aad-1b5e-4a92-dd32-75c74e647d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\n"
          ]
        }
      ],
      "source": [
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ghRDY2OwzDd",
        "outputId": "9aeed7a1-9620-416e-dfba-3533ef764188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.35  Python-3.11.9 torch-2.3.1+cpu CPU (AMD Ryzen 9 7940HS w/ Radeon 780M Graphics)\n",
            "Setup complete  (16 CPUs, 15.2 GB RAM, 415.0/449.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iY8mFDCzw3rb"
      },
      "outputs": [],
      "source": [
        "model_path = \"./YOLOv8 best.pt\"\n",
        "model = YOLO(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMGjQTtU6NfA",
        "outputId": "5e799b36-c40a-4e92-e10a-f7c3fa8dcbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 11 frames at 1 frame per second.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Create a directory to store the frames\n",
        "output_dir = 'frames'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Load the video\n",
        "video_path = './REM Beauty Eyeshadow Palette Unboxing.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)  # Get frames per second of the video\n",
        "frame_interval = int(fps)  # We want 1 frame per second\n",
        "\n",
        "frame_count = 0\n",
        "frame_index = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if frame_count % frame_interval == 0:\n",
        "        # Save the frame as an image file\n",
        "        frame_filename = os.path.join(output_dir, f'frame_{frame_index:04d}.jpg')\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        frame_index += 1\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f'Extracted {frame_index} frames at 1 frame per second.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fWpIito7EsE",
        "outputId": "87f235e0-7c3d-4106-aa2b-5b455f99f34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0000.jpg: 800x480 (no detections), 733.5ms\n",
            "Speed: 15.6ms preprocess, 733.5ms inference, 15.6ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0001.jpg: 800x480 (no detections), 662.6ms\n",
            "Speed: 13.5ms preprocess, 662.6ms inference, 15.6ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0002.jpg: 800x480 (no detections), 620.0ms\n",
            "Speed: 5.5ms preprocess, 620.0ms inference, 17.3ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0003.jpg: 800x480 1 makeup, 645.5ms\n",
            "Speed: 8.2ms preprocess, 645.5ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0004.jpg: 800x480 1 makeup, 647.3ms\n",
            "Speed: 0.0ms preprocess, 647.3ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0005.jpg: 800x480 1 makeup, 646.8ms\n",
            "Speed: 7.6ms preprocess, 646.8ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0006.jpg: 800x480 1 makeup, 657.3ms\n",
            "Speed: 4.5ms preprocess, 657.3ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0007.jpg: 800x480 (no detections), 635.9ms\n",
            "Speed: 9.3ms preprocess, 635.9ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0008.jpg: 800x480 (no detections), 662.9ms\n",
            "Speed: 4.4ms preprocess, 662.9ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0009.jpg: 800x480 1 makeup, 655.4ms\n",
            "Speed: 0.6ms preprocess, 655.4ms inference, 5.5ms postprocess per image at shape (1, 3, 800, 480)\n",
            "\n",
            "image 1/1 c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\backend\\Object Detection\\frames\\frame_0010.jpg: 800x480 (no detections), 611.6ms\n",
            "Speed: 9.6ms preprocess, 611.6ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 480)\n"
          ]
        }
      ],
      "source": [
        "frames_dir = 'frames'\n",
        "detection_results = []\n",
        "\n",
        "# Loop through each frame and run the YOLO model\n",
        "for frame_file in sorted(os.listdir(frames_dir)):\n",
        "    frame_id = int(frame_file.split('_')[1].split('.')[0])  # Extract frame ID from filename\n",
        "    frame_path = os.path.join(frames_dir, frame_file)\n",
        "\n",
        "    results = model.predict(source=frame_path, save=False)  # Run the YOLO model\n",
        "\n",
        "    detected = 0  # Initialize detection flag for the frame\n",
        "    detected_classes = []  # List to store detected class names\n",
        "\n",
        "    # Check if any objects were detected and record their class names\n",
        "    for result in results:\n",
        "        if len(result.boxes) > 0:\n",
        "            detected = 1\n",
        "            for detection in result.boxes:\n",
        "                class_name = model.names[int(detection.cls)]  # Get class name\n",
        "                detected_classes.append(class_name)\n",
        "\n",
        "    # Store the result\n",
        "    detection_results.append({'frame_id': frame_id, 'detected': detected, 'classes': detected_classes})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTaUAsxm8GBD",
        "outputId": "0098572f-fa61-4b0d-f3ad-71011ef135cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection Results:\n",
            "Frame 0: No Detection (0)\n",
            "Frame 1: No Detection (0)\n",
            "Frame 2: No Detection (0)\n",
            "Frame 3: Detected (1), Classes: makeup\n",
            "Frame 4: Detected (1), Classes: makeup\n",
            "Frame 5: Detected (1), Classes: makeup\n",
            "Frame 6: Detected (1), Classes: makeup\n",
            "Frame 7: No Detection (0)\n",
            "Frame 8: No Detection (0)\n",
            "Frame 9: Detected (1), Classes: makeup\n",
            "Frame 10: No Detection (0)\n"
          ]
        }
      ],
      "source": [
        "print(\"Detection Results:\")\n",
        "for result in detection_results:\n",
        "    if result['detected'] == 1:\n",
        "        classes_detected = ', '.join(result['classes'])\n",
        "        print(f\"Frame {result['frame_id']}: Detected (1), Classes: {classes_detected}\")\n",
        "    else:\n",
        "        print(f\"Frame {result['frame_id']}: No Detection (0)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZsyN0ajbJ_x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
