{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users DataFrame:\n",
      "   user_id  age  gender     occupation\n",
      "0        1   43  Female   Professional\n",
      "1        2   54    Male        Student\n",
      "2        3   20    Male  Self-employed\n",
      "3        4   34   Other   Professional\n",
      "4        5   69  Female   Professional\n",
      "Products DataFrame:\n",
      "   product_id  category   price  rating  \\\n",
      "0           1    Sports  340.62     3.0   \n",
      "1           2     Books  125.90     3.8   \n",
      "2           3    Sports  137.85     4.4   \n",
      "3           4  Clothing  113.46     1.6   \n",
      "4           5     Books  330.76     2.6   \n",
      "\n",
      "                                         description  video_id  \n",
      "0  This Sports is comfortable and lightweight, de...      1001  \n",
      "1  Our Books offers a must-read experience with b...      1002  \n",
      "2  Achieve your best with our professional-grade ...      1003  \n",
      "3  This Clothing combines trendy style with comfo...      1004  \n",
      "4  Our Books offers a classic experience with inf...      1005  \n",
      "Interactions DataFrame:\n",
      "   user_id  product_id interaction_type           timestamp\n",
      "0      482         123             view 2023-01-01 00:00:00\n",
      "1      927         153         purchase 2023-01-01 00:01:00\n",
      "2       68         310             view 2023-01-01 00:02:00\n",
      "3      530         166             view 2023-01-01 00:03:00\n",
      "4      222         376             view 2023-01-01 00:04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_22452\\2876443316.py:103: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Number of users\n",
    "num_users = 1000\n",
    "\n",
    "# Generate synthetic user data\n",
    "user_ids = np.arange(1, num_users + 1)\n",
    "user_ages = np.random.randint(18, 70, size=num_users)  # Ages between 18 and 70\n",
    "user_genders = np.random.choice(['Male', 'Female', 'Other'], size=num_users, p=[0.45, 0.45, 0.10])\n",
    "user_occupation = np.random.choice(['Student', 'Professional', 'Retired', 'Self-employed'], size=num_users, p=[0.3, 0.4, 0.2, 0.1])\n",
    "\n",
    "# Create DataFrame\n",
    "users = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'age': user_ages,\n",
    "    'gender': user_genders,\n",
    "    'occupation': user_occupation\n",
    "})\n",
    "\n",
    "print(\"Users DataFrame:\")\n",
    "print(users.head())\n",
    "\n",
    "# Number of products\n",
    "num_products = 500\n",
    "\n",
    "# Generate synthetic product data\n",
    "product_ids = np.arange(1, num_products + 1)\n",
    "product_categories = np.random.choice(['Electronics', 'Books', 'Clothing', 'Home', 'Beauty', 'Sports'], size=num_products)\n",
    "product_prices = np.round(np.random.uniform(5.0, 500.0, size=num_products), 2)  # Prices between $5 and $500\n",
    "product_ratings = np.round(np.random.uniform(1.0, 5.0, size=num_products), 1)  # Ratings between 1.0 and 5.0\n",
    "\n",
    "# Generate unique video IDs for products\n",
    "video_ids = np.arange(1001, 1001 + num_products)  # Unique video IDs starting from 1001\n",
    "\n",
    "# Keywords and templates for descriptions\n",
    "description_keywords = {\n",
    "    'Electronics': ['latest technology', 'high-performance', 'durable', 'compact', 'user-friendly'],\n",
    "    'Books': ['bestselling', 'engaging', 'classic', 'informative', 'must-read'],\n",
    "    'Clothing': ['stylish', 'comfortable', 'trendy', 'breathable', 'versatile'],\n",
    "    'Home': ['modern', 'elegant', 'cozy', 'durable', 'functional'],\n",
    "    'Beauty': ['premium quality', 'natural ingredients', 'long-lasting', 'hypoallergenic', 'luxurious'],\n",
    "    'Sports': ['high-performance', 'durable', 'lightweight', 'comfortable', 'professional-grade']\n",
    "}\n",
    "\n",
    "description_templates = {\n",
    "    'Electronics': [\n",
    "        \"This {category} item features {adjective1} design and {adjective2} functionality. It's {adjective3} and {adjective4}, perfect for everyday use.\",\n",
    "        \"Experience the {adjective1} of our {category} with this {adjective2} product. It's {adjective3} and {adjective4}, ensuring high performance.\"\n",
    "    ],\n",
    "    'Books': [\n",
    "        \"Dive into this {category} with our {adjective1} and {adjective2} read. It's {adjective3} and {adjective4}, a {adjective5} addition to any collection.\",\n",
    "        \"Our {category} offers a {adjective1} experience with {adjective2} insights. It's {adjective3} and {adjective4}, ideal for any reader.\"\n",
    "    ],\n",
    "    'Clothing': [\n",
    "        \"Our {category} is {adjective1} and {adjective2}, perfect for {adjective3} wear. It's {adjective4} and {adjective5}, making it a staple in any wardrobe.\",\n",
    "        \"This {category} combines {adjective1} style with {adjective2} comfort. It's {adjective3} and {adjective4}, suitable for all occasions.\"\n",
    "    ],\n",
    "    'Home': [\n",
    "        \"Enhance your living space with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for any home.\",\n",
    "        \"Our {category} is {adjective1} and {adjective2}, designed for {adjective3} use. It's {adjective4} and {adjective5}, adding a touch of elegance to your home.\"\n",
    "    ],\n",
    "    'Beauty': [\n",
    "        \"Experience {adjective1} and {adjective2} care with our {category}. It's {adjective3} and {adjective4}, perfect for a {adjective5} routine.\",\n",
    "        \"Our {category} features {adjective1} ingredients and {adjective2} results. It's {adjective3} and {adjective4}, ensuring a {adjective5} glow.\"\n",
    "    ],\n",
    "    'Sports': [\n",
    "        \"Achieve your best with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for {adjective5} performance.\",\n",
    "        \"This {category} is {adjective1} and {adjective2}, designed for {adjective3} activities. It's {adjective4} and {adjective5}, ideal for any sports enthusiast.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to generate a random description based on category\n",
    "def generate_description(category):\n",
    "    adjectives = random.sample(description_keywords[category], 5)\n",
    "    template = random.choice(description_templates[category])\n",
    "    return template.format(category=category, adjective1=adjectives[0], adjective2=adjectives[1], adjective3=adjectives[2], adjective4=adjectives[3], adjective5=adjectives[4])\n",
    "\n",
    "# Generate product descriptions\n",
    "product_descriptions = [generate_description(cat) for cat in product_categories]\n",
    "\n",
    "# Create DataFrame with descriptions\n",
    "products = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'category': product_categories,\n",
    "    'price': product_prices,\n",
    "    'rating': product_ratings,\n",
    "    'description': product_descriptions,\n",
    "    'video_id': video_ids  # Include the video IDs\n",
    "})\n",
    "\n",
    "print(\"Products DataFrame:\")\n",
    "print(products.head())\n",
    "\n",
    "# Number of interactions\n",
    "num_interactions = 10000\n",
    "\n",
    "# Generate synthetic interaction data\n",
    "interaction_user_ids = np.random.choice(user_ids, size=num_interactions)\n",
    "interaction_product_ids = np.random.choice(product_ids, size=num_interactions)\n",
    "interaction_types = np.random.choice(['view', 'click', 'like', 'comment', 'share', 'purchase'], size=num_interactions, p=[0.4, 0.3, 0.1, 0.1, 0.05, 0.05])\n",
    "interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n",
    "\n",
    "# Create DataFrame\n",
    "interactions = pd.DataFrame({\n",
    "    'user_id': interaction_user_ids,\n",
    "    'product_id': interaction_product_ids,\n",
    "    'interaction_type': interaction_types,\n",
    "    'timestamp': interaction_timestamps\n",
    "})\n",
    "\n",
    "print(\"Interactions DataFrame:\")\n",
    "print(interactions.head())\n",
    "\n",
    "# Save DataFrames to CSV\n",
    "users.to_csv('synthetic_users.csv', index=False)\n",
    "products.to_csv('synthetic_products.csv', index=False)\n",
    "interactions.to_csv('synthetic_interactions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  product_id  interaction           timestamp\n",
      "0      143         117            3 2023-01-01 00:00:00\n",
      "1       20         500            4 2023-01-01 00:01:00\n",
      "2      192         212            4 2023-01-01 00:02:00\n",
      "3      849         426            5 2023-01-01 00:03:00\n",
      "4      362         142            1 2023-01-01 00:04:00\n",
      "      user_id  product_id  interaction           timestamp\n",
      "0           1          12          1.0 2023-01-06 08:39:00\n",
      "1           1          25          5.0 2023-01-02 12:57:00\n",
      "2           1          68          1.0 2023-01-03 13:42:00\n",
      "3           1          82          4.0 2023-01-07 17:09:00\n",
      "4           1         108          1.0 2023-01-03 09:18:00\n",
      "...       ...         ...          ...                 ...\n",
      "9886     1000         162          3.5 2023-01-06 04:12:00\n",
      "9887     1000         256          2.0 2023-01-03 07:31:00\n",
      "9888     1000         290          5.0 2023-01-01 11:22:00\n",
      "9889     1000         381          2.0 2023-01-07 06:48:00\n",
      "9890     1000         385          5.0 2023-01-07 13:10:00\n",
      "\n",
      "[9891 rows x 4 columns]\n",
      "product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id  493  494  495  496  497  498  499  500  \n",
      "user_id                                             \n",
      "1           3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2           0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  \n",
      "3           0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "products[['price', 'rating']] = scaler.fit_transform(products[['price', 'rating']])\n",
    "\n",
    "# Vectorize product descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "product_descriptions_matrix = vectorizer.fit_transform(products['description'])\n",
    "\n",
    "# Combine product metadata into a single feature set\n",
    "product_features = np.hstack((products[['price', 'rating']], product_descriptions_matrix.toarray()))\n",
    "\n",
    "# Aggregate the interactions by taking the average rating for each user-product pair\n",
    "aggregated_interactions = interactions.groupby(['user_id', 'product_id']).mean().reset_index()\n",
    "print (interactions.head())\n",
    "print (aggregated_interactions)\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply Truncated SVD for matrix factorization\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "user_factors = svd.fit_transform(user_item_sparse)\n",
    "item_factors = svd.components_.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  video_id category     price  rating  \\\n",
      "0             1         1   Beauty  0.628723   0.450   \n",
      "370         371       371   Beauty  0.669694   0.450   \n",
      "376         377       377   Beauty  0.692623   0.500   \n",
      "56           57        57   Beauty  0.594279   0.575   \n",
      "215         216       216   Beauty  0.804752   0.475   \n",
      "27           28        28   Beauty  0.627993   0.300   \n",
      "184         185       185   Beauty  0.803677   0.425   \n",
      "28           29        29   Beauty  0.673201   0.300   \n",
      "394         395       395   Beauty  0.730857   0.650   \n",
      "51           52        52   Beauty  0.559024   0.275   \n",
      "\n",
      "                                           description  \n",
      "0    Experience long-lasting and natural ingredient...  \n",
      "370  Experience premium quality and luxurious care ...  \n",
      "376  Experience hypoallergenic and natural ingredie...  \n",
      "56   Experience luxurious and natural ingredients c...  \n",
      "215  Experience long-lasting and natural ingredient...  \n",
      "27   Experience natural ingredients and premium qua...  \n",
      "184  Experience hypoallergenic and luxurious care w...  \n",
      "28   Experience natural ingredients and hypoallerge...  \n",
      "394  Experience natural ingredients and hypoallerge...  \n",
      "51   Experience luxurious and hypoallergenic care w...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between product features\n",
    "cosine_similarities = cosine_similarity(product_features)\n",
    "\n",
    "# Function to recommend similar products\n",
    "def recommend_products(product_id, top_n=10):\n",
    "    product_idx = products.index[products['product_id'] == product_id][0]\n",
    "    similar_indices = cosine_similarities[product_idx].argsort()[-top_n:][::-1]\n",
    "    similar_products = products.iloc[similar_indices]\n",
    "    return similar_products\n",
    "\n",
    "# Example usage\n",
    "recommended_products = recommend_products(product_id=1)\n",
    "print(recommended_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  video_id  category     price  rating  \\\n",
      "24           25        25  Clothing  0.899447   0.275   \n",
      "235         236       236  Clothing  0.981754   0.900   \n",
      "476         477       477  Clothing  0.938938   0.525   \n",
      "197         198       198  Clothing  0.820930   0.550   \n",
      "34           35        35  Clothing  0.913394   0.375   \n",
      "231         232       232  Clothing  0.876599   0.675   \n",
      "252         253       253  Clothing  0.829100   0.550   \n",
      "314         315       315  Clothing  0.790480   0.475   \n",
      "76           77        77  Clothing  0.787540   0.575   \n",
      "162         163       163  Clothing  0.949176   0.950   \n",
      "\n",
      "                                           description  \n",
      "24   This Clothing combines breathable style with c...  \n",
      "235  Our Clothing is breathable and comfortable, pe...  \n",
      "476  This Clothing combines breathable style with t...  \n",
      "197  Our Clothing is stylish and comfortable, perfe...  \n",
      "34   Our Clothing is trendy and stylish, perfect fo...  \n",
      "231  Our Clothing is breathable and stylish, perfec...  \n",
      "252  Our Clothing is stylish and breathable, perfec...  \n",
      "314  Our Clothing is versatile and stylish, perfect...  \n",
      "76   Our Clothing is stylish and versatile, perfect...  \n",
      "162  This Clothing combines trendy style with versa...  \n"
     ]
    }
   ],
   "source": [
    "# Function to get hybrid recommendations\n",
    "def hybrid_recommendations(user_id, top_n=10):\n",
    "    user_idx = users.index[users['user_id'] == user_id][0]\n",
    "    user_interactions = user_item_matrix.iloc[user_idx].values\n",
    "    \n",
    "    # Weighted average of collaborative filtering and content-based recommendations\n",
    "    cf_recommendations = user_factors[user_idx].dot(item_factors.T)\n",
    "    cb_recommendations = cosine_similarities.dot(user_interactions)\n",
    "    \n",
    "    combined_scores = cf_recommendations + cb_recommendations\n",
    "    top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    return products.iloc[top_indices]\n",
    "\n",
    "# Example usage\n",
    "user_recommendations = hybrid_recommendations(user_id=1)\n",
    "print(user_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id      493  494  495  496       497  498  499  500  \n",
      "user_id                                                      \n",
      "1           2.01096  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
      "2           0.00000  0.0  0.0  0.0  3.032653  0.0  0.0  0.0  \n",
      "3           0.00000  0.0  5.0  0.0  0.000000  0.0  0.0  0.0  \n",
      "4           0.00000  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
      "5           0.00000  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply time decay factor to interactions\n",
    "interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
    "max_time = interactions['timestamp'].max()\n",
    "\n",
    "# Define a time decay function\n",
    "def time_decay(t, max_time, decay_rate=0.1):\n",
    "    return np.exp(-decay_rate * (max_time - t).days)\n",
    "\n",
    "# Apply the time decay factor\n",
    "interactions['decay_factor'] = interactions['timestamp'].apply(lambda t: time_decay(t, max_time))\n",
    "interactions['interaction'] = interactions['interaction'] * interactions['decay_factor']\n",
    "\n",
    "# Option 1: Aggregating duplicate entries\n",
    "# aggregated_interactions = interactions.groupby(['user_id', 'product_id']).sum().reset_index()\n",
    "\n",
    "# Option 2: Keeping only the latest interaction\n",
    "latest_interactions = interactions.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'product_id'], keep='last')\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "# For Option 1:\n",
    "# user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# For Option 2:\n",
    "user_item_matrix = latest_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.7865934032340487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(user_factors, item_factors, test_data):\n",
    "    test_preds = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user_idx = users.index[users['user_id'] == row['user_id']][0]\n",
    "        product_idx = products.index[products['product_id'] == row['product_id']][0]\n",
    "        pred_rating = user_factors[user_idx].dot(item_factors[product_idx])\n",
    "        test_preds.append(pred_rating)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(test_data['interaction'], test_preds))\n",
    "    return test_rmse\n",
    "\n",
    "# Example usage\n",
    "test_rmse = evaluate_model(user_factors, item_factors, test_data)\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/recommend', methods=['GET'])\n",
    "def recommend():\n",
    "    user_id = int(request.args.get('user_id'))\n",
    "    top_n = int(request.args.get('top_n', 10))\n",
    "    \n",
    "    recommendations = hybrid_recommendations(user_id, top_n)\n",
    "    return jsonify(recommendations.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
