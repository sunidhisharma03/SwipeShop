{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age  gender    occupation\n",
      "0        1   63  Female  Professional\n",
      "1        2   34  Female  Professional\n",
      "2        3   68    Male       Retired\n",
      "3        4   52  Female       Student\n",
      "4        5   65    Male       Student\n",
      "   product_id     category   price  rating  \\\n",
      "0           1     Clothing  358.38     4.3   \n",
      "1           2       Sports  191.28     3.1   \n",
      "2           3        Books  348.96     2.7   \n",
      "3           4  Electronics  245.82     2.0   \n",
      "4           5     Clothing   39.30     1.2   \n",
      "\n",
      "                                         description  \n",
      "0  This Clothing combines breathable style with v...  \n",
      "1  This Sports is high-performance and durable, d...  \n",
      "2  Dive into this Books with our must-read and cl...  \n",
      "3  This Electronics item features latest technolo...  \n",
      "4  Our Clothing is trendy and breathable, perfect...  \n",
      "   user_id  product_id  interaction           timestamp\n",
      "0      292         416            1 2023-01-01 00:00:00\n",
      "1      488         483            2 2023-01-01 00:01:00\n",
      "2       24         390            3 2023-01-01 00:02:00\n",
      "3      715         323            5 2023-01-01 00:03:00\n",
      "4      651         180            2 2023-01-01 00:04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_19560\\1060621169.py:97: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Number of users\n",
    "num_users = 1000\n",
    "\n",
    "# Generate synthetic user data\n",
    "user_ids = np.arange(1, num_users + 1)\n",
    "user_ages = np.random.randint(18, 70, size=num_users)  # Ages between 18 and 70\n",
    "user_genders = np.random.choice(['Male', 'Female', 'Other'], size=num_users, p=[0.45, 0.45, 0.10])\n",
    "user_occupation = np.random.choice(['Student', 'Professional', 'Retired', 'Self-employed'], size=num_users, p=[0.3, 0.4, 0.2, 0.1])\n",
    "\n",
    "# Create DataFrame\n",
    "users = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'age': user_ages,\n",
    "    'gender': user_genders,\n",
    "    'occupation': user_occupation\n",
    "})\n",
    "\n",
    "print(users.head())\n",
    "\n",
    "# Number of products\n",
    "num_products = 500\n",
    "\n",
    "# Generate synthetic product data\n",
    "product_ids = np.arange(1, num_products + 1)\n",
    "product_categories = np.random.choice(['Electronics', 'Books', 'Clothing', 'Home', 'Beauty', 'Sports'], size=num_products)\n",
    "product_prices = np.round(np.random.uniform(5.0, 500.0, size=num_products), 2)  # Prices between $5 and $500\n",
    "product_ratings = np.round(np.random.uniform(1.0, 5.0, size=num_products), 1)  # Ratings between 1.0 and 5.0\n",
    "\n",
    "# Keywords and templates for descriptions\n",
    "description_keywords = {\n",
    "    'Electronics': ['latest technology', 'high-performance', 'durable', 'compact', 'user-friendly'],\n",
    "    'Books': ['bestselling', 'engaging', 'classic', 'informative', 'must-read'],\n",
    "    'Clothing': ['stylish', 'comfortable', 'trendy', 'breathable', 'versatile'],\n",
    "    'Home': ['modern', 'elegant', 'cozy', 'durable', 'functional'],\n",
    "    'Beauty': ['premium quality', 'natural ingredients', 'long-lasting', 'hypoallergenic', 'luxurious'],\n",
    "    'Sports': ['high-performance', 'durable', 'lightweight', 'comfortable', 'professional-grade']\n",
    "}\n",
    "\n",
    "description_templates = {\n",
    "    'Electronics': [\n",
    "        \"This {category} item features {adjective1} design and {adjective2} functionality. It's {adjective3} and {adjective4}, perfect for everyday use.\",\n",
    "        \"Experience the {adjective1} of our {category} with this {adjective2} product. It's {adjective3} and {adjective4}, ensuring high performance.\"\n",
    "    ],\n",
    "    'Books': [\n",
    "        \"Dive into this {category} with our {adjective1} and {adjective2} read. It's {adjective3} and {adjective4}, a {adjective5} addition to any collection.\",\n",
    "        \"Our {category} offers a {adjective1} experience with {adjective2} insights. It's {adjective3} and {adjective4}, ideal for any reader.\"\n",
    "    ],\n",
    "    'Clothing': [\n",
    "        \"Our {category} is {adjective1} and {adjective2}, perfect for {adjective3} wear. It's {adjective4} and {adjective5}, making it a staple in any wardrobe.\",\n",
    "        \"This {category} combines {adjective1} style with {adjective2} comfort. It's {adjective3} and {adjective4}, suitable for all occasions.\"\n",
    "    ],\n",
    "    'Home': [\n",
    "        \"Enhance your living space with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for any home.\",\n",
    "        \"Our {category} is {adjective1} and {adjective2}, designed for {adjective3} use. It's {adjective4} and {adjective5}, adding a touch of elegance to your home.\"\n",
    "    ],\n",
    "    'Beauty': [\n",
    "        \"Experience {adjective1} and {adjective2} care with our {category}. It's {adjective3} and {adjective4}, perfect for a {adjective5} routine.\",\n",
    "        \"Our {category} features {adjective1} ingredients and {adjective2} results. It's {adjective3} and {adjective4}, ensuring a {adjective5} glow.\"\n",
    "    ],\n",
    "    'Sports': [\n",
    "        \"Achieve your best with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for {adjective5} performance.\",\n",
    "        \"This {category} is {adjective1} and {adjective2}, designed for {adjective3} activities. It's {adjective4} and {adjective5}, ideal for any sports enthusiast.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to generate a random description based on category\n",
    "def generate_description(category):\n",
    "    adjectives = random.sample(description_keywords[category], 5)\n",
    "    template = random.choice(description_templates[category])\n",
    "    return template.format(category=category, adjective1=adjectives[0], adjective2=adjectives[1], adjective3=adjectives[2], adjective4=adjectives[3], adjective5=adjectives[4])\n",
    "\n",
    "# Generate product descriptions\n",
    "product_descriptions = [generate_description(cat) for cat in product_categories]\n",
    "\n",
    "# Create DataFrame with descriptions\n",
    "products = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'category': product_categories,\n",
    "    'price': product_prices,\n",
    "    'rating': product_ratings,\n",
    "    'description': product_descriptions\n",
    "})\n",
    "\n",
    "print(products.head())\n",
    "\n",
    "# Number of interactions\n",
    "num_interactions = 10000\n",
    "\n",
    "# Generate synthetic interaction data\n",
    "interaction_user_ids = np.random.choice(user_ids, size=num_interactions)\n",
    "interaction_product_ids = np.random.choice(product_ids, size=num_interactions)\n",
    "interaction_ratings = np.random.randint(1, 6, size=num_interactions)  # Ratings between 1 and 5\n",
    "interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n",
    "\n",
    "# Create DataFrame\n",
    "interactions = pd.DataFrame({\n",
    "    'user_id': interaction_user_ids,\n",
    "    'product_id': interaction_product_ids,\n",
    "    'interaction': interaction_ratings,\n",
    "    'timestamp': interaction_timestamps\n",
    "})\n",
    "\n",
    "print(interactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id  493  494  495  496  497  498  499  500  \n",
      "user_id                                             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "products[['price', 'rating']] = scaler.fit_transform(products[['price', 'rating']])\n",
    "\n",
    "# Vectorize product descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "product_descriptions_matrix = vectorizer.fit_transform(products['description'])\n",
    "\n",
    "# Combine product metadata into a single feature set\n",
    "product_features = np.hstack((products[['price', 'rating']], product_descriptions_matrix.toarray()))\n",
    "\n",
    "# Aggregate the interactions by taking the average rating for each user-product pair\n",
    "aggregated_interactions = interactions.groupby(['user_id', 'product_id']).mean().reset_index()\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply Truncated SVD for matrix factorization\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "user_factors = svd.fit_transform(user_item_sparse)\n",
    "item_factors = svd.components_.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  category     price  rating  \\\n",
      "0             1  Clothing  0.714728   0.825   \n",
      "162         163  Clothing  0.592764   1.000   \n",
      "68           69  Clothing  0.755039   0.450   \n",
      "287         288  Clothing  0.704843   0.700   \n",
      "130         131  Clothing  0.666700   0.825   \n",
      "296         297  Clothing  0.613568   0.625   \n",
      "356         357  Clothing  0.668706   0.925   \n",
      "443         444  Clothing  0.697024   0.950   \n",
      "166         167  Clothing  0.306217   0.550   \n",
      "422         423  Clothing  0.792898   0.675   \n",
      "\n",
      "                                           description  \n",
      "0    This Clothing combines breathable style with v...  \n",
      "162  This Clothing combines stylish style with brea...  \n",
      "68   This Clothing combines stylish style with comf...  \n",
      "287  This Clothing combines trendy style with versa...  \n",
      "130  This Clothing combines stylish style with tren...  \n",
      "296  This Clothing combines trendy style with styli...  \n",
      "356  This Clothing combines trendy style with comfo...  \n",
      "443  This Clothing combines breathable style with t...  \n",
      "166  This Clothing combines versatile style with st...  \n",
      "422  This Clothing combines versatile style with br...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between product features\n",
    "cosine_similarities = cosine_similarity(product_features)\n",
    "\n",
    "# Function to recommend similar products\n",
    "def recommend_products(product_id, top_n=10):\n",
    "    product_idx = products.index[products['product_id'] == product_id][0]\n",
    "    similar_indices = cosine_similarities[product_idx].argsort()[-top_n:][::-1]\n",
    "    similar_products = products.iloc[similar_indices]\n",
    "    return similar_products\n",
    "\n",
    "# Example usage\n",
    "recommended_products = recommend_products(product_id=1)\n",
    "print(recommended_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id     category     price  rating  \\\n",
      "414         415       Sports  0.799421   0.875   \n",
      "357         358         Home  0.984929   1.000   \n",
      "265         266  Electronics  1.000000   0.675   \n",
      "492         493         Home  0.930541   0.800   \n",
      "347         348  Electronics  0.917212   1.000   \n",
      "210         211       Beauty  0.841291   0.975   \n",
      "13           14  Electronics  0.910203   0.950   \n",
      "267         268         Home  0.984828   0.625   \n",
      "73           74         Home  0.867746   0.975   \n",
      "250         251       Beauty  0.776349   0.650   \n",
      "\n",
      "                                           description  \n",
      "414  This Sports is lightweight and high-performanc...  \n",
      "357  Enhance your living space with our modern and ...  \n",
      "265  This Electronics item features compact design ...  \n",
      "492  Our Home is elegant and functional, designed f...  \n",
      "347  Experience the high-performance of our Electro...  \n",
      "210  Experience natural ingredients and hypoallerge...  \n",
      "13   Experience the compact of our Electronics with...  \n",
      "267  Enhance your living space with our cozy and el...  \n",
      "73   Enhance your living space with our functional ...  \n",
      "250  Experience premium quality and luxurious care ...  \n"
     ]
    }
   ],
   "source": [
    "# Function to get hybrid recommendations\n",
    "def hybrid_recommendations(user_id, top_n=10):\n",
    "    user_idx = users.index[users['user_id'] == user_id][0]\n",
    "    user_interactions = user_item_matrix.iloc[user_idx].values\n",
    "    \n",
    "    # Weighted average of collaborative filtering and content-based recommendations\n",
    "    cf_recommendations = user_factors[user_idx].dot(item_factors.T)\n",
    "    cb_recommendations = cosine_similarities.dot(user_interactions)\n",
    "    \n",
    "    combined_scores = cf_recommendations + cb_recommendations\n",
    "    top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    return products.iloc[top_indices]\n",
    "\n",
    "# Example usage\n",
    "user_recommendations = hybrid_recommendations(user_id=1)\n",
    "print(user_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id  1    2    3    4    5    6         7    8    9    10   ...  491  \\\n",
      "user_id                                                            ...        \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  2.456192  0.0  0.0  0.0  ...  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "\n",
      "product_id  492  493  494  495  496  497  498  499  500  \n",
      "user_id                                                  \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply time decay factor to interactions\n",
    "interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
    "max_time = interactions['timestamp'].max()\n",
    "\n",
    "# Define a time decay function\n",
    "def time_decay(t, max_time, decay_rate=0.1):\n",
    "    return np.exp(-decay_rate * (max_time - t).days)\n",
    "\n",
    "# Apply the time decay factor\n",
    "interactions['decay_factor'] = interactions['timestamp'].apply(lambda t: time_decay(t, max_time))\n",
    "interactions['interaction'] = interactions['interaction'] * interactions['decay_factor']\n",
    "\n",
    "# Option 1: Aggregating duplicate entries\n",
    "# aggregated_interactions = interactions.groupby(['user_id', 'product_id']).sum().reset_index()\n",
    "\n",
    "# Option 2: Keeping only the latest interaction\n",
    "latest_interactions = interactions.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'product_id'], keep='last')\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "# For Option 1:\n",
    "# user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# For Option 2:\n",
    "user_item_matrix = latest_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.786305927387092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(user_factors, item_factors, test_data):\n",
    "    test_preds = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user_idx = users.index[users['user_id'] == row['user_id']][0]\n",
    "        product_idx = products.index[products['product_id'] == row['product_id']][0]\n",
    "        pred_rating = user_factors[user_idx].dot(item_factors[product_idx])\n",
    "        test_preds.append(pred_rating)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(test_data['interaction'], test_preds))\n",
    "    return test_rmse\n",
    "\n",
    "# Example usage\n",
    "test_rmse = evaluate_model(user_factors, item_factors, test_data)\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/recommend', methods=['GET'])\n",
    "def recommend():\n",
    "    user_id = int(request.args.get('user_id'))\n",
    "    top_n = int(request.args.get('top_n', 10))\n",
    "    \n",
    "    recommendations = hybrid_recommendations(user_id, top_n)\n",
    "    return jsonify(recommendations.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
