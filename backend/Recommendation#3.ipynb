{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age  gender occupation\n",
      "0        1   28  Female    Retired\n",
      "1        2   50   Other    Student\n",
      "2        3   19  Female    Retired\n",
      "3        4   67    Male    Retired\n",
      "4        5   41    Male    Student\n",
      "   product_id     category   price  rating  \\\n",
      "0           1     Clothing  173.49     1.1   \n",
      "1           2     Clothing  157.47     3.2   \n",
      "2           3       Sports   67.25     1.4   \n",
      "3           4     Clothing  139.35     3.5   \n",
      "4           5  Electronics  229.67     2.2   \n",
      "\n",
      "                                         description  \n",
      "0  Our Clothing is versatile and trendy, perfect ...  \n",
      "1  Our Clothing is trendy and stylish, perfect fo...  \n",
      "2  Achieve your best with our durable and high-pe...  \n",
      "3  This Clothing combines comfortable style with ...  \n",
      "4  Experience the high-performance of our Electro...  \n",
      "   user_id  product_id  interaction           timestamp\n",
      "0      886         412            5 2023-01-01 00:00:00\n",
      "1      574          45            4 2023-01-01 00:01:00\n",
      "2      549         371            5 2023-01-01 00:02:00\n",
      "3       56          29            3 2023-01-01 00:03:00\n",
      "4      161         183            3 2023-01-01 00:04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_25348\\1060621169.py:97: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Number of users\n",
    "num_users = 1000\n",
    "\n",
    "# Generate synthetic user data\n",
    "user_ids = np.arange(1, num_users + 1)\n",
    "user_ages = np.random.randint(18, 70, size=num_users)  # Ages between 18 and 70\n",
    "user_genders = np.random.choice(['Male', 'Female', 'Other'], size=num_users, p=[0.45, 0.45, 0.10])\n",
    "user_occupation = np.random.choice(['Student', 'Professional', 'Retired', 'Self-employed'], size=num_users, p=[0.3, 0.4, 0.2, 0.1])\n",
    "\n",
    "# Create DataFrame\n",
    "users = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'age': user_ages,\n",
    "    'gender': user_genders,\n",
    "    'occupation': user_occupation\n",
    "})\n",
    "\n",
    "print(users.head())\n",
    "\n",
    "# Number of products\n",
    "num_products = 500\n",
    "\n",
    "# Generate synthetic product data\n",
    "product_ids = np.arange(1, num_products + 1)\n",
    "product_categories = np.random.choice(['Electronics', 'Books', 'Clothing', 'Home', 'Beauty', 'Sports'], size=num_products)\n",
    "product_prices = np.round(np.random.uniform(5.0, 500.0, size=num_products), 2)  # Prices between $5 and $500\n",
    "product_ratings = np.round(np.random.uniform(1.0, 5.0, size=num_products), 1)  # Ratings between 1.0 and 5.0\n",
    "\n",
    "# Keywords and templates for descriptions\n",
    "description_keywords = {\n",
    "    'Electronics': ['latest technology', 'high-performance', 'durable', 'compact', 'user-friendly'],\n",
    "    'Books': ['bestselling', 'engaging', 'classic', 'informative', 'must-read'],\n",
    "    'Clothing': ['stylish', 'comfortable', 'trendy', 'breathable', 'versatile'],\n",
    "    'Home': ['modern', 'elegant', 'cozy', 'durable', 'functional'],\n",
    "    'Beauty': ['premium quality', 'natural ingredients', 'long-lasting', 'hypoallergenic', 'luxurious'],\n",
    "    'Sports': ['high-performance', 'durable', 'lightweight', 'comfortable', 'professional-grade']\n",
    "}\n",
    "\n",
    "description_templates = {\n",
    "    'Electronics': [\n",
    "        \"This {category} item features {adjective1} design and {adjective2} functionality. It's {adjective3} and {adjective4}, perfect for everyday use.\",\n",
    "        \"Experience the {adjective1} of our {category} with this {adjective2} product. It's {adjective3} and {adjective4}, ensuring high performance.\"\n",
    "    ],\n",
    "    'Books': [\n",
    "        \"Dive into this {category} with our {adjective1} and {adjective2} read. It's {adjective3} and {adjective4}, a {adjective5} addition to any collection.\",\n",
    "        \"Our {category} offers a {adjective1} experience with {adjective2} insights. It's {adjective3} and {adjective4}, ideal for any reader.\"\n",
    "    ],\n",
    "    'Clothing': [\n",
    "        \"Our {category} is {adjective1} and {adjective2}, perfect for {adjective3} wear. It's {adjective4} and {adjective5}, making it a staple in any wardrobe.\",\n",
    "        \"This {category} combines {adjective1} style with {adjective2} comfort. It's {adjective3} and {adjective4}, suitable for all occasions.\"\n",
    "    ],\n",
    "    'Home': [\n",
    "        \"Enhance your living space with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for any home.\",\n",
    "        \"Our {category} is {adjective1} and {adjective2}, designed for {adjective3} use. It's {adjective4} and {adjective5}, adding a touch of elegance to your home.\"\n",
    "    ],\n",
    "    'Beauty': [\n",
    "        \"Experience {adjective1} and {adjective2} care with our {category}. It's {adjective3} and {adjective4}, perfect for a {adjective5} routine.\",\n",
    "        \"Our {category} features {adjective1} ingredients and {adjective2} results. It's {adjective3} and {adjective4}, ensuring a {adjective5} glow.\"\n",
    "    ],\n",
    "    'Sports': [\n",
    "        \"Achieve your best with our {adjective1} and {adjective2} {category}. It's {adjective3} and {adjective4}, perfect for {adjective5} performance.\",\n",
    "        \"This {category} is {adjective1} and {adjective2}, designed for {adjective3} activities. It's {adjective4} and {adjective5}, ideal for any sports enthusiast.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to generate a random description based on category\n",
    "def generate_description(category):\n",
    "    adjectives = random.sample(description_keywords[category], 5)\n",
    "    template = random.choice(description_templates[category])\n",
    "    return template.format(category=category, adjective1=adjectives[0], adjective2=adjectives[1], adjective3=adjectives[2], adjective4=adjectives[3], adjective5=adjectives[4])\n",
    "\n",
    "# Generate product descriptions\n",
    "product_descriptions = [generate_description(cat) for cat in product_categories]\n",
    "\n",
    "# Create DataFrame with descriptions\n",
    "products = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'category': product_categories,\n",
    "    'price': product_prices,\n",
    "    'rating': product_ratings,\n",
    "    'description': product_descriptions\n",
    "})\n",
    "\n",
    "print(products.head())\n",
    "\n",
    "# Number of interactions\n",
    "num_interactions = 10000\n",
    "\n",
    "# Generate synthetic interaction data\n",
    "interaction_user_ids = np.random.choice(user_ids, size=num_interactions)\n",
    "interaction_product_ids = np.random.choice(product_ids, size=num_interactions)\n",
    "interaction_ratings = np.random.randint(1, 6, size=num_interactions)  # Ratings between 1 and 5\n",
    "interaction_timestamps = pd.date_range(start='2023-01-01', periods=num_interactions, freq='T')  # Random timestamps\n",
    "\n",
    "# Create DataFrame\n",
    "interactions = pd.DataFrame({\n",
    "    'user_id': interaction_user_ids,\n",
    "    'product_id': interaction_product_ids,\n",
    "    'interaction': interaction_ratings,\n",
    "    'timestamp': interaction_timestamps\n",
    "})\n",
    "\n",
    "print(interactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id  493  494  495  496  497  498  499  500  \n",
      "user_id                                             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "products[['price', 'rating']] = scaler.fit_transform(products[['price', 'rating']])\n",
    "\n",
    "# Vectorize product descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "product_descriptions_matrix = vectorizer.fit_transform(products['description'])\n",
    "\n",
    "# Combine product metadata into a single feature set\n",
    "product_features = np.hstack((products[['price', 'rating']], product_descriptions_matrix.toarray()))\n",
    "\n",
    "# Aggregate the interactions by taking the average rating for each user-product pair\n",
    "aggregated_interactions = interactions.groupby(['user_id', 'product_id']).mean().reset_index()\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply Truncated SVD for matrix factorization\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "user_factors = svd.fit_transform(user_item_sparse)\n",
    "item_factors = svd.components_.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  category     price  rating  \\\n",
      "0             1  Clothing  0.339617   0.025   \n",
      "295         296  Clothing  0.460820   0.075   \n",
      "247         248  Clothing  0.234941   0.100   \n",
      "422         423  Clothing  0.488025   0.050   \n",
      "208         209  Clothing  0.365245   0.175   \n",
      "391         392  Clothing  0.197540   0.075   \n",
      "94           95  Clothing  0.501092   0.125   \n",
      "85           86  Clothing  0.311178   0.250   \n",
      "143         144  Clothing  0.557870   0.250   \n",
      "428         429  Clothing  0.363142   0.325   \n",
      "\n",
      "                                           description  \n",
      "0    Our Clothing is versatile and trendy, perfect ...  \n",
      "295  Our Clothing is trendy and versatile, perfect ...  \n",
      "247  Our Clothing is stylish and comfortable, perfe...  \n",
      "422  Our Clothing is trendy and versatile, perfect ...  \n",
      "208  Our Clothing is trendy and comfortable, perfec...  \n",
      "391  Our Clothing is versatile and stylish, perfect...  \n",
      "94   Our Clothing is trendy and versatile, perfect ...  \n",
      "85   Our Clothing is versatile and stylish, perfect...  \n",
      "143  Our Clothing is stylish and trendy, perfect fo...  \n",
      "428  Our Clothing is breathable and trendy, perfect...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between product features\n",
    "cosine_similarities = cosine_similarity(product_features)\n",
    "\n",
    "# Function to recommend similar products\n",
    "def recommend_products(product_id, top_n=10):\n",
    "    product_idx = products.index[products['product_id'] == product_id][0]\n",
    "    similar_indices = cosine_similarities[product_idx].argsort()[-top_n:][::-1]\n",
    "    similar_products = products.iloc[similar_indices]\n",
    "    return similar_products\n",
    "\n",
    "# Example usage\n",
    "recommended_products = recommend_products(product_id=1)\n",
    "print(recommended_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  category     price  rating  \\\n",
      "130         131      Home  0.997006   0.800   \n",
      "371         372      Home  0.830373   0.950   \n",
      "56           57      Home  0.946135   0.925   \n",
      "463         464      Home  0.845261   0.900   \n",
      "307         308      Home  0.817691   0.975   \n",
      "187         188      Home  0.999130   0.750   \n",
      "95           96      Home  0.694284   0.825   \n",
      "459         460  Clothing  0.991767   1.000   \n",
      "131         132  Clothing  0.584550   0.800   \n",
      "345         346      Home  0.971399   0.675   \n",
      "\n",
      "                                           description  \n",
      "130  Enhance your living space with our durable and...  \n",
      "371  Our Home is functional and cozy, designed for ...  \n",
      "56   Our Home is durable and elegant, designed for ...  \n",
      "463  Enhance your living space with our cozy and mo...  \n",
      "307  Enhance your living space with our elegant and...  \n",
      "187  Our Home is elegant and cozy, designed for fun...  \n",
      "95   Enhance your living space with our durable and...  \n",
      "459  Our Clothing is comfortable and breathable, pe...  \n",
      "131  Our Clothing is stylish and breathable, perfec...  \n",
      "345  Our Home is durable and modern, designed for e...  \n"
     ]
    }
   ],
   "source": [
    "# Function to get hybrid recommendations\n",
    "def hybrid_recommendations(user_id, top_n=10):\n",
    "    user_idx = users.index[users['user_id'] == user_id][0]\n",
    "    user_interactions = user_item_matrix.iloc[user_idx].values\n",
    "    \n",
    "    # Weighted average of collaborative filtering and content-based recommendations\n",
    "    cf_recommendations = user_factors[user_idx].dot(item_factors.T)\n",
    "    cb_recommendations = cosine_similarities.dot(user_interactions)\n",
    "    \n",
    "    combined_scores = cf_recommendations + cb_recommendations\n",
    "    top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    return products.iloc[top_indices]\n",
    "\n",
    "# Example usage\n",
    "user_recommendations = hybrid_recommendations(user_id=1)\n",
    "print(user_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id  493  494  495  496  497  498       499       500  \n",
      "user_id                                                       \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.898658  0.000000  \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.449329  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply time decay factor to interactions\n",
    "interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
    "max_time = interactions['timestamp'].max()\n",
    "\n",
    "# Define a time decay function\n",
    "def time_decay(t, max_time, decay_rate=0.1):\n",
    "    return np.exp(-decay_rate * (max_time - t).days)\n",
    "\n",
    "# Apply the time decay factor\n",
    "interactions['decay_factor'] = interactions['timestamp'].apply(lambda t: time_decay(t, max_time))\n",
    "interactions['interaction'] = interactions['interaction'] * interactions['decay_factor']\n",
    "\n",
    "# Option 1: Aggregating duplicate entries\n",
    "# aggregated_interactions = interactions.groupby(['user_id', 'product_id']).sum().reset_index()\n",
    "\n",
    "# Option 2: Keeping only the latest interaction\n",
    "latest_interactions = interactions.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'product_id'], keep='last')\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "# For Option 1:\n",
    "# user_item_matrix = aggregated_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# For Option 2:\n",
    "user_item_matrix = latest_interactions.pivot(index='user_id', columns='product_id', values='interaction').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "print(user_item_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.4600050108597842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(user_factors, item_factors, test_data):\n",
    "    test_preds = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user_idx = users.index[users['user_id'] == row['user_id']][0]\n",
    "        product_idx = products.index[products['product_id'] == row['product_id']][0]\n",
    "        pred_rating = user_factors[user_idx].dot(item_factors[product_idx])\n",
    "        test_preds.append(pred_rating)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(test_data['interaction'], test_preds))\n",
    "    return test_rmse\n",
    "\n",
    "# Example usage\n",
    "test_rmse = evaluate_model(user_factors, item_factors, test_data)\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\My Files\\KU\\5th sem\\Project\\SwipeShop\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/recommend', methods=['GET'])\n",
    "def recommend():\n",
    "    user_id = int(request.args.get('user_id'))\n",
    "    top_n = int(request.args.get('top_n', 10))\n",
    "    \n",
    "    recommendations = hybrid_recommendations(user_id, top_n)\n",
    "    return jsonify(recommendations.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
